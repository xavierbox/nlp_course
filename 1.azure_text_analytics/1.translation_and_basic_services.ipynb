{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with  the Azure AI language service  \n",
    "\n",
    "<p>Azure AI Language is designed to help you extract information from text. It provides functionality that you can use for:\n",
    "\n",
    "<ul>\n",
    "<li>Language detection - determining the language in which text is written.</li>\n",
    "<li>Key phrase extraction - identifying important words and phrases in the text that indicate the main points.</li>\n",
    "<li>Sentiment analysis - quantifying how positive or negative the text is.</li>\n",
    "<li>Named entity recognition - detecting references to entities, including people, locations, time periods, organizations, and more.</li>\n",
    "<li>Entity linking - identifying specific entities by providing reference links to Wikipedia articles.</li>\n",
    "</ul>\n",
    "\n",
    "## Provision an Azure AI Language resource\n",
    "[1] https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/2-provision-resource\n",
    "\n",
    "[2] https://learn.microsoft.com/en-us/azure/ai-services/multi-service-resource?tabs=multiservice%2Cwindows&pivots=azportal\n",
    "\n",
    "\n",
    "1. Create a resource group \n",
    "2. Create an AI-service (multiservice resource)\n",
    "\n",
    "## Consume the service \n",
    "\n",
    "\n",
    "All the services work in a similar manner. A laguage service is first created, which is \n",
    "accessed via an endpoint and a key.\n",
    "From the client application, a TextAnalyticsClient is instantiated.\n",
    "Such client provides an  API with methods such as  detect_language, analyze_sentiment and recognize_entities. The methods all take the same arguments. Yet the return (a json) differes \n",
    "depending on the action. \n",
    "\n",
    "Some example code here:\n",
    "\n",
    "https://microsoftlearning.github.io/mslearn-ai-language/Instructions/Exercises/01-analyze-text.html\n",
    "\n",
    "As an alternative, Azure provides a SDK client that wraps around the service. The client is instantiate with some required creadentials and a resource location. Then the client provides an API to detect languages, and translate among other functionality.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example services  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect language service \n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/language-service/language-detection/overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "import pprint \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "text_analytics_client = TextAnalyticsClient(endpoint, AzureKeyCredential(key))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This capability is useful for content stores that \\\n",
    "collect arbitrary text, where language is unknown. Another \\\n",
    "scenario could involve a chat bot. If a user starts a session \\\n",
    "with the chat bot, language detection can be used to determine \\\n",
    "which language they are using and allow you to configure your \\\n",
    "bot responses in the appropriate language.\"\n",
    "\n",
    "documents =  [text, \"Bonjour tout le monde\", 'Es un dia precioso', 'voy a matarlos a todos']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the client for language detection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DetectLanguageResult(id=0, primary_language=DetectedLanguage(name=English, iso6391_name=en, confidence_score=1.0), warnings=[], statistics=None, is_error=False, kind=LanguageDetection),\n",
      " DetectLanguageResult(id=1, primary_language=DetectedLanguage(name=French, iso6391_name=fr, confidence_score=1.0), warnings=[], statistics=None, is_error=False, kind=LanguageDetection),\n",
      " DetectLanguageResult(id=2, primary_language=DetectedLanguage(name=Spanish, iso6391_name=es, confidence_score=1.0), warnings=[], statistics=None, is_error=False, kind=LanguageDetection),\n",
      " DetectLanguageResult(id=3, primary_language=DetectedLanguage(name=Spanish, iso6391_name=es, confidence_score=1.0), warnings=[], statistics=None, is_error=False, kind=LanguageDetection)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "detectedLanguage = text_analytics_client.detect_language(documents = documents )\n",
    "pprint( detectedLanguage ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This capability is useful for content st', 'sentiment', 'neutral'),\n",
      " ('Bonjour tout le monde', 'sentiment', 'positive'),\n",
      " ('Es un dia precioso', 'sentiment', 'positive'),\n",
      " ('voy a matarlos a todos', 'sentiment', 'negative')]\n",
      "[SentimentConfidenceScores(positive=0.03, neutral=0.97, negative=0.0),\n",
      " SentimentConfidenceScores(positive=0.77, neutral=0.21, negative=0.01),\n",
      " SentimentConfidenceScores(positive=0.98, neutral=0.02, negative=0.01),\n",
      " SentimentConfidenceScores(positive=0.09, neutral=0.3, negative=0.61)]\n"
     ]
    }
   ],
   "source": [
    "detectedSentiment = text_analytics_client.analyze_sentiment(documents = documents )\n",
    "\n",
    "pprint( [ (documents[n][0:40], 'sentiment', r['sentiment']) for n,r in enumerate(detectedSentiment) ] )\n",
    "pprint([ r['confidence_scores'] for r in detectedSentiment ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key phrases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExtractKeyPhrasesResult(id=0, key_phrases=['content stores', 'arbitrary text', 'chat bot', 'bot responses', 'language detection', 'appropriate language', 'capability', 'scenario', 'user', 'session'], warnings=[], statistics=None, is_error=False, kind=KeyPhraseExtraction),\n",
       " ExtractKeyPhrasesResult(id=1, key_phrases=['Bonjour', 'monde'], warnings=[], statistics=None, is_error=False, kind=KeyPhraseExtraction),\n",
       " ExtractKeyPhrasesResult(id=2, key_phrases=['dia', 'precioso'], warnings=[], statistics=None, is_error=False, kind=KeyPhraseExtraction),\n",
       " ExtractKeyPhrasesResult(id=3, key_phrases=[], warnings=[], statistics=None, is_error=False, kind=KeyPhraseExtraction)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = text_analytics_client.extract_key_phrases(documents=documents)\n",
    "phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (draft)Consume multiple services in one call to the endpoint. \n",
    "\n",
    "Using the SDK \n",
    "\n",
    "Reference: \n",
    "https://learn.microsoft.com/en-us/python/api/overview/azure/ai-textanalytics-readme?view=azure-python#detect-language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document text: We went to Contoso Steakhouse located at midtown NYC last week for a dinner party, and we adore the spot! They provide marvelous food and they have a great menu. The chief cook happens to be the owner (I think his name is John Doe) and he is super nice, coming out of the kitchen and greeted us all.\n",
      "...Results of Recognize Entities Action:\n",
      "......Entity: Contoso Steakhouse\n",
      ".........Category: Location\n",
      ".........Confidence Score: 0.99\n",
      ".........Offset: 11\n",
      "......Entity: midtown\n",
      ".........Category: Location\n",
      ".........Confidence Score: 0.52\n",
      ".........Offset: 41\n",
      "......Entity: NYC\n",
      ".........Category: Location\n",
      ".........Confidence Score: 1.0\n",
      ".........Offset: 49\n",
      "......Entity: last week\n",
      ".........Category: DateTime\n",
      ".........Confidence Score: 1.0\n",
      ".........Offset: 53\n",
      "......Entity: dinner party\n",
      ".........Category: Event\n",
      ".........Confidence Score: 0.78\n",
      ".........Offset: 69\n",
      "......Entity: food\n",
      ".........Category: Product\n",
      ".........Confidence Score: 0.57\n",
      ".........Offset: 129\n",
      "......Entity: chief cook\n",
      ".........Category: PersonType\n",
      ".........Confidence Score: 0.71\n",
      ".........Offset: 166\n",
      "......Entity: owner\n",
      ".........Category: PersonType\n",
      ".........Confidence Score: 0.98\n",
      ".........Offset: 195\n",
      "......Entity: John Doe\n",
      ".........Category: Person\n",
      ".........Confidence Score: 0.99\n",
      ".........Offset: 222\n",
      "......Entity: kitchen\n",
      ".........Category: Location\n",
      ".........Confidence Score: 0.97\n",
      ".........Offset: 272\n",
      "...Results of Recognize PII Entities action:\n",
      "......Entity: chief cook\n",
      ".........Category: PersonType\n",
      ".........Confidence Score: 0.71\n",
      "......Entity: owner\n",
      ".........Category: PersonType\n",
      ".........Confidence Score: 0.98\n",
      "......Entity: John Doe\n",
      ".........Category: Person\n",
      ".........Confidence Score: 0.99\n",
      "...Results of Extract Key Phrases action:\n",
      "......Key Phrases: ['Contoso Steakhouse', 'midtown NYC', 'dinner party', 'marvelous food', 'great menu', 'chief cook', 'John Doe', 'spot', 'owner', 'name', 'kitchen']\n",
      "...Results of Recognize Linked Entities action:\n",
      "......Entity name: Steakhouse\n",
      ".........Data source: Wikipedia\n",
      ".........Data source language: en\n",
      ".........Data source entity ID: Steakhouse\n",
      ".........Data source URL: https://en.wikipedia.org/wiki/Steakhouse\n",
      ".........Document matches:\n",
      "............Match text: Steakhouse\n",
      "............Confidence Score: 0.75\n",
      "............Offset: 19\n",
      "............Length: 10\n",
      "......Entity name: New York City\n",
      ".........Data source: Wikipedia\n",
      ".........Data source language: en\n",
      ".........Data source entity ID: New York City\n",
      ".........Data source URL: https://en.wikipedia.org/wiki/New_York_City\n",
      ".........Document matches:\n",
      "............Match text: NYC\n",
      "............Confidence Score: 0.37\n",
      "............Offset: 49\n",
      "............Length: 3\n",
      "......Entity name: John Doe\n",
      ".........Data source: Wikipedia\n",
      ".........Data source language: en\n",
      ".........Data source entity ID: John Doe\n",
      ".........Data source URL: https://en.wikipedia.org/wiki/John_Doe\n",
      ".........Document matches:\n",
      "............Match text: John Doe\n",
      "............Confidence Score: 0.05\n",
      "............Offset: 222\n",
      "............Length: 8\n",
      "...Results of Analyze Sentiment action:\n",
      "......Overall sentiment: positive\n",
      "......Scores: positive=1.0;                 neutral=0.0;                 negative=0.0 \n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Document text: We enjoyed very much dining in the place! The Sirloin steak I ordered was tender and juicy, and the place was impeccably clean. You can even pre-order from their online menu at www.contososteakhouse.com, call 312-555-0176 or send email to order@contososteakhouse.com! The only complaint I have is the food didn't come fast enough. Overall I highly recommend it!\n",
      "...Results of Recognize Entities Action:\n",
      "......Entity: place\n",
      ".........Category: Location\n",
      ".........Confidence Score: 0.65\n",
      ".........Offset: 35\n",
      "......Entity: Sirloin steak\n",
      ".........Category: Product\n",
      ".........Confidence Score: 0.98\n",
      ".........Offset: 46\n",
      "......Entity: www.contososteakhouse.com\n",
      ".........Category: URL\n",
      ".........Confidence Score: 0.8\n",
      ".........Offset: 177\n",
      "......Entity: 312-555-0176\n",
      ".........Category: PhoneNumber\n",
      ".........Confidence Score: 0.8\n",
      ".........Offset: 209\n",
      "......Entity: order@contososteakhouse.com\n",
      ".........Category: Email\n",
      ".........Confidence Score: 0.8\n",
      ".........Offset: 239\n",
      "......Entity: food\n",
      ".........Category: Product\n",
      ".........Confidence Score: 0.9\n",
      ".........Offset: 301\n",
      "...Results of Recognize PII Entities action:\n",
      "......Entity: www.contososteakhouse.com\n",
      ".........Category: URL\n",
      ".........Confidence Score: 0.8\n",
      "......Entity: 312-555-0176\n",
      ".........Category: PhoneNumber\n",
      ".........Confidence Score: 0.8\n",
      "......Entity: order@contososteakhouse.com\n",
      ".........Category: Email\n",
      ".........Confidence Score: 0.8\n",
      "...Results of Extract Key Phrases action:\n",
      "......Key Phrases: ['The Sirloin steak', 'online menu', 'dining', 'place', 'order', 'contososteakhouse', 'email', 'complaint', 'food']\n",
      "...Results of Recognize Linked Entities action:\n",
      "......Entity name: Sirloin steak\n",
      ".........Data source: Wikipedia\n",
      ".........Data source language: en\n",
      ".........Data source entity ID: Sirloin steak\n",
      ".........Data source URL: https://en.wikipedia.org/wiki/Sirloin_steak\n",
      ".........Document matches:\n",
      "............Match text: Sirloin steak\n",
      "............Confidence Score: 0.69\n",
      "............Offset: 46\n",
      "............Length: 13\n",
      "...Results of Analyze Sentiment action:\n",
      "......Overall sentiment: mixed\n",
      "......Scores: positive=0.75;                 neutral=0.0;                 negative=0.25 \n",
      "\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import (\n",
    "    TextAnalyticsClient,\n",
    "    RecognizeEntitiesAction,\n",
    "    RecognizeLinkedEntitiesAction,\n",
    "    RecognizePiiEntitiesAction,\n",
    "    ExtractKeyPhrasesAction,\n",
    "    AnalyzeSentimentAction,\n",
    ")\n",
    "\n",
    "endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(key),\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    'We went to Contoso Steakhouse located at midtown NYC last week for a dinner party, and we adore the spot! '\n",
    "    'They provide marvelous food and they have a great menu. The chief cook happens to be the owner (I think his name is John Doe) '\n",
    "    'and he is super nice, coming out of the kitchen and greeted us all.'\n",
    "    ,\n",
    "\n",
    "    'We enjoyed very much dining in the place! '\n",
    "    'The Sirloin steak I ordered was tender and juicy, and the place was impeccably clean. You can even pre-order from their '\n",
    "    'online menu at www.contososteakhouse.com, call 312-555-0176 or send email to order@contososteakhouse.com! '\n",
    "    'The only complaint I have is the food didn\\'t come fast enough. Overall I highly recommend it!'\n",
    "]\n",
    "\n",
    "poller = text_analytics_client.begin_analyze_actions(\n",
    "    documents,\n",
    "    display_name=\"Sample Text Analysis\",\n",
    "    actions=[\n",
    "        RecognizeEntitiesAction(),\n",
    "        RecognizePiiEntitiesAction(),\n",
    "        ExtractKeyPhrasesAction(),\n",
    "        RecognizeLinkedEntitiesAction(),\n",
    "        AnalyzeSentimentAction(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "document_results = poller.result()\n",
    "for doc, action_results in zip(documents, document_results):\n",
    "    print(f\"\\nDocument text: {doc}\")\n",
    "    for result in action_results:\n",
    "        if result.kind == \"EntityRecognition\":\n",
    "            print(\"...Results of Recognize Entities Action:\")\n",
    "            for entity in result.entities:\n",
    "                print(f\"......Entity: {entity.text}\")\n",
    "                print(f\".........Category: {entity.category}\")\n",
    "                print(f\".........Confidence Score: {entity.confidence_score}\")\n",
    "                print(f\".........Offset: {entity.offset}\")\n",
    "\n",
    "        elif result.kind == \"PiiEntityRecognition\":\n",
    "            print(\"...Results of Recognize PII Entities action:\")\n",
    "            for pii_entity in result.entities:\n",
    "                print(f\"......Entity: {pii_entity.text}\")\n",
    "                print(f\".........Category: {pii_entity.category}\")\n",
    "                print(f\".........Confidence Score: {pii_entity.confidence_score}\")\n",
    "\n",
    "        elif result.kind == \"KeyPhraseExtraction\":\n",
    "            print(\"...Results of Extract Key Phrases action:\")\n",
    "            print(f\"......Key Phrases: {result.key_phrases}\")\n",
    "\n",
    "        elif result.kind == \"EntityLinking\":\n",
    "            print(\"...Results of Recognize Linked Entities action:\")\n",
    "            for linked_entity in result.entities:\n",
    "                print(f\"......Entity name: {linked_entity.name}\")\n",
    "                print(f\".........Data source: {linked_entity.data_source}\")\n",
    "                print(f\".........Data source language: {linked_entity.language}\")\n",
    "                print(\n",
    "                    f\".........Data source entity ID: {linked_entity.data_source_entity_id}\"\n",
    "                )\n",
    "                print(f\".........Data source URL: {linked_entity.url}\")\n",
    "                print(\".........Document matches:\")\n",
    "                for match in linked_entity.matches:\n",
    "                    print(f\"............Match text: {match.text}\")\n",
    "                    print(f\"............Confidence Score: {match.confidence_score}\")\n",
    "                    print(f\"............Offset: {match.offset}\")\n",
    "                    print(f\"............Length: {match.length}\")\n",
    "\n",
    "        elif result.kind == \"SentimentAnalysis\":\n",
    "            print(\"...Results of Analyze Sentiment action:\")\n",
    "            print(f\"......Overall sentiment: {result.sentiment}\")\n",
    "            print(\n",
    "                f\"......Scores: positive={result.confidence_scores.positive}; \\\n",
    "                neutral={result.confidence_scores.neutral}; \\\n",
    "                negative={result.confidence_scores.negative} \\n\"\n",
    "            )\n",
    "\n",
    "        elif result.is_error is True:\n",
    "            print(\n",
    "                f\"...Is an error with code '{result.error.code}' and message '{result.error.message}'\"\n",
    "            )\n",
    "\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure translation service \n",
    "\n",
    "Azure AI Translator is a cloud-based machine translation service you can use to translate text and documents with a simple REST API call.Alternatively, Azure provides a SDKL for several programming languages to interact with the cloud service via  a TextTranslationClient  \n",
    "\n",
    "Limits:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/Translator/service-limits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the REST API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quiero manejar tu carro', 'I want to drive your car'),\n",
       " ('Hace mucho calor en la playa', \"It's very hot on the beach\"),\n",
       " ('estoy ladillado', \"I'm\"),\n",
       " ('estoy aburrido', 'I am bored')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, uuid, json\n",
    "\n",
    "TRANSLATOR_ENPOINT  = os.environ[\"TRANSLATOR_ENPOINT\"]\n",
    "TRANSLATOR_LOCATION = os.environ[\"TRANSLATOR_LOCATION\"]\n",
    "TRANSLATOR_KEY      = os.environ[\"TRANSLATOR_KEY\"]\n",
    "\n",
    "\n",
    "#this is a custom wrapper around the service \n",
    "class TranslatorClient:\n",
    "    \n",
    "    def __init__(self, key, endpoint, location):\n",
    "        self.enpoint=  endpoint\n",
    "        self.key = key \n",
    "        self.location = location \n",
    "\n",
    "    def detect_language( self, txt ):\n",
    "        path = '/detect?api-version=3.0'\n",
    "        constructed_url = self.enpoint + path\n",
    "\n",
    "        body = [{\n",
    "        'text': txt\n",
    "        }]\n",
    "        request = requests.post(constructed_url, headers=self._get_header(), json=body)\n",
    "        response = request.json()\n",
    "\n",
    "        return response[0]['language'] \n",
    "\n",
    "    def _get_header( self ):\n",
    "        headers = {\n",
    "            'Ocp-Apim-Subscription-Key': self.key,\n",
    "            # location required if you're using a multi-service or regional (not global) resource.\n",
    "            'Ocp-Apim-Subscription-Region': self.location,\n",
    "            'Content-type': 'application/json',\n",
    "            'X-ClientTraceId': str(uuid.uuid4())\n",
    "        }\n",
    "          \n",
    "        return headers \n",
    "\n",
    "    def translate( self,  to_language,  documents, from_language = None ):\n",
    "\n",
    "        if from_language is None:\n",
    "            #assume only one language and the first document should be able to pick it up \n",
    "            from_language = self.detect_language( documents[0]['text'] )\n",
    "\n",
    "        params = {\n",
    "            'api-version': '3.0',\n",
    "            'from': from_language,\n",
    "            'to': [ to_language]\n",
    "        }\n",
    "\n",
    "      \n",
    "\n",
    "        # You can pass more than one object in body.\n",
    "        body = documents\n",
    "\n",
    "        response = requests.post(endpoint+'/translate', params=params, headers=self._get_header(), json=body)\n",
    "        return  response\n",
    "\n",
    "\n",
    "\n",
    "# Add your key and endpoint\n",
    "key      = TRANSLATOR_KEY\n",
    "endpoint = TRANSLATOR_ENPOINT \n",
    "location = TRANSLATOR_LOCATION\n",
    "\n",
    "documents = [{'text': 'quiero manejar tu carro'},\n",
    "             {'text': 'Hace mucho calor en la playa'}, \n",
    "             {'text':'estoy ladillado'},\n",
    "             {'text':'estoy aburrido'}\n",
    "             ]\n",
    "\n",
    "\n",
    "client=  TranslatorClient( key, endpoint, location )\n",
    "\n",
    "response = client.translate( to_language = 'en', documents = documents )\n",
    "\n",
    "translations = [ (documents[n]['text'], item['translations'][0]['text']) for n,item in  enumerate(response.json()) ]\n",
    "\n",
    "translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the SDK \n",
    "\n",
    "The SDK is a wrapper around the same API service, quite similar to the one created above.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/translator/quickstart-text-sdk?pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.translation.text import TextTranslationClient#, TranslatorCredential\n",
    "from azure.ai.translation.text.models import InputTextItem\n",
    "from azure.core.exceptions import HttpResponseError\n",
    " \n",
    "#see \n",
    "#https://learn.microsoft.com/en-us/python/api/azure-ai-translation-text/azure.ai.translation.text.texttranslationclient?view=azure-python#azure-ai-translation-text-texttranslationclient-translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected languages of the input text: en with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'This is a test.'.\n",
      "Detected languages of the input text: en with score: 0.0.\n",
      "Text was translated to: 'en' and the result is: '--*******-----******-------'.\n",
      "Detected languages of the input text: en with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'This is text number 5'.\n",
      "[{'This is a test.': {'translation': 'This is a test.', 'laguage_score': 1.0}}, {'--*******-----******-------': {'translation': '--*******-----******-------', 'laguage_score': 0.0}}, {'This is text number 5': {'translation': 'This is text number 5', 'laguage_score': 1.0}}]\n"
     ]
    }
   ],
   "source": [
    "def get_text_translation_multiple_inputs( text_translator, input_text_elements:list[str], to_language: list[str] ):\n",
    "    # [START get_text_translation_multiple_inputs]\n",
    "\n",
    "    results = []\n",
    "    if isinstance( to_language,str): to_language = [ to_language ]\n",
    "    try:\n",
    "        translations = text_translator.translate(body=input_text_elements, to_language=to_language)\n",
    "          \n",
    "\n",
    "\n",
    "        for n,translation in enumerate(translations):\n",
    "            #print( translation )\n",
    "\n",
    "            language_score = translation.detected_language.score \n",
    "            language_translation = translation.translations[0].text if translation.translations else None\n",
    "\n",
    "            results.append( { input_text_elements[n] : { 'translation': language_translation, 'laguage_score': language_score}} ) \n",
    "            \n",
    "            print(\n",
    "                f\"Detected languages of the input text: {translation.detected_language.language if translation.detected_language else None} with score: {translation.detected_language.score if translation.detected_language else None}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Text was translated to: '{translation.translations[0].to if translation.translations else None}' and the result is: '{translation.translations[0].text if translation.translations else None}'.\"\n",
    "            )\n",
    "\n",
    "    except HttpResponseError as exception:\n",
    "        if exception.error is not None:\n",
    "            print(f\"Error Code: {exception.error.code}\")\n",
    "            print(f\"Message: {exception.error.message}\")\n",
    "\n",
    "        return None \n",
    "    # [END get_text_translation_multiple_inputs]\n",
    "\n",
    "    return results \n",
    "  \n",
    " \n",
    "key      = os.environ[\"TRANSLATOR_KEY\"]\n",
    "endpoint = os.environ[\"TRANSLATOR_ENPOINT\"]\n",
    "location = os.environ[\"TRANSLATOR_LOCATION\"]\n",
    "\n",
    "text_translator = TextTranslationClient(credential=AzureKeyCredential( key ), region = location )\n",
    "\n",
    "#Each translate request is limited to 50,000 characters, across all the target languages.\n",
    "input_text_elements = ['This is a test.', '--*******-----******-------', 'This is text number 5']\n",
    "\n",
    "translation_results = get_text_translation_multiple_inputs(text_translator, input_text_elements,'en' )  \n",
    "print( translation_results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected languages of the input text: en with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'This is a test.'.\n",
      "Detected languages of the input text: es with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'This is a test.'.\n",
      "Detected languages of the input text: de with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'This is a test.'.\n",
      "Detected languages of the input text: en with score: 0.0.\n",
      "Text was translated to: 'en' and the result is: '--*******-----******-------'.\n",
      "Detected languages of the input text: es with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'This is text number 5'.\n",
      "Detected languages of the input text: es with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'I'm a happy face emoji 😀'.\n",
      "[{'This is a test.': {'translation': 'This is a test.', 'laguage_score': 1.0}}, {'Esto es una prueba.': {'translation': 'This is a test.', 'laguage_score': 1.0}}, {'Dies ist ein Test.': {'translation': 'This is a test.', 'laguage_score': 1.0}}, {'--*******-----******-------': {'translation': '--*******-----******-------', 'laguage_score': 0.0}}, {'Este es el texto numero 5': {'translation': 'This is text number 5', 'laguage_score': 1.0}}, {'Yo soy un emoji 😀 de carita feliz': {'translation': \"I'm a happy face emoji 😀\", 'laguage_score': 1.0}}]\n"
     ]
    }
   ],
   "source": [
    "def get_text_translation_multiple_inputs( text_translator, input_text_elements:list[str], to_language: list[str] ):\n",
    "    # [START get_text_translation_multiple_inputs]\n",
    "\n",
    "    results = []\n",
    "    if isinstance( to_language,str): to_language = [ to_language ]\n",
    "    try:\n",
    "        translations = text_translator.translate(body=input_text_elements, to_language=to_language)\n",
    "\n",
    "        for n,translation in enumerate(translations):\n",
    "            #print( translation )\n",
    "\n",
    "            language_score = translation.detected_language.score \n",
    "            language_translation = translation.translations[0].text if translation.translations else None\n",
    "\n",
    "            results.append( { input_text_elements[n] : { 'translation': language_translation, 'laguage_score': language_score}} ) \n",
    "            \n",
    "            print(\n",
    "                f\"Detected languages of the input text: {translation.detected_language.language if translation.detected_language else None} with score: {translation.detected_language.score if translation.detected_language else None}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Text was translated to: '{translation.translations[0].to if translation.translations else None}' and the result is: '{translation.translations[0].text if translation.translations else None}'.\"\n",
    "            )\n",
    "\n",
    "    except HttpResponseError as exception:\n",
    "        if exception.error is not None:\n",
    "            print(f\"Error Code: {exception.error.code}\")\n",
    "            print(f\"Message: {exception.error.message}\")\n",
    "\n",
    "        return None \n",
    "    # [END get_text_translation_multiple_inputs]\n",
    "\n",
    "    return results \n",
    "  \n",
    "to_language = [\"en\"]\n",
    "input_text_elements = [\n",
    "            \"This is a test.\",\n",
    "            \"Esto es una prueba.\",\n",
    "            \"Dies ist ein Test.\",\n",
    "            \"--*******-----******-------\",\n",
    "            \"Este es el texto numero 5\",\n",
    "            \"Yo soy un emoji \\U0001f600 de carita feliz\"     \n",
    "        ]\n",
    "key      = TRANSLATOR_KEY\n",
    "endpoint = TRANSLATOR_ENPOINT \n",
    "location = TRANSLATOR_LOCATION\n",
    "\n",
    "text_translator = TextTranslationClient(credential=AzureKeyCredential( key ), region = location )\n",
    "\n",
    "#Each translate request is limited to 50,000 characters, across all the target languages.\n",
    "translation_results = get_text_translation_multiple_inputs(text_translator, input_text_elements,to_language )  \n",
    "print( translation_results )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation, language detection and sentiment analysis\n",
    "\n",
    "The former two can be done directly with the function defined above. For the sentiment analysis part, we can use the \n",
    "text analytics descried a the beginning of the notebook, and pass to it the translated documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test.',\n",
       " 'This is a test.',\n",
       " 'This is a test.',\n",
       " '--*******-----******-------',\n",
       " 'This is text number 5',\n",
       " \"I'm a happy face emoji 😀\"]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_documents = [ value['translation'] for x in translation_results  for key, value in x.items()  ]\n",
    "english_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This is a test.', 'sentiment', 'neutral'), ('This is a test.', 'sentiment', 'neutral'), ('This is a test.', 'sentiment', 'neutral'), ('--*******-----******-------', 'sentiment', 'neutral'), ('This is text number 5', 'sentiment', 'neutral'), (\"I'm a happy face emoji 😀\", 'sentiment', 'positive')]\n",
      "[SentimentConfidenceScores(positive=0.0, neutral=0.99, negative=0.0), SentimentConfidenceScores(positive=0.0, neutral=0.99, negative=0.0), SentimentConfidenceScores(positive=0.0, neutral=0.99, negative=0.0), SentimentConfidenceScores(positive=0.01, neutral=0.94, negative=0.05), SentimentConfidenceScores(positive=0.08, neutral=0.91, negative=0.01), SentimentConfidenceScores(positive=0.99, neutral=0.01, negative=0.0)]\n"
     ]
    }
   ],
   "source": [
    "text_analytics_endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "text_analytics_key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=text_analytics_endpoint,credential=AzureKeyCredential(text_analytics_key))\n",
    "english_documents = [ value['translation'] for x in translation_results  for key, value in x.items()  ]\n",
    "\n",
    "\n",
    "sentiment = text_analytics_client.analyze_sentiment(documents = english_documents )\n",
    "print( [ (english_documents[n][0:40], 'sentiment', r['sentiment']) for n,r in enumerate(sentiment) ] )\n",
    "print([ r['confidence_scores'] for r in sentiment ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'This is a test.': {'laguage_score': 1.0, 'translation': 'This is a test.'},\n",
      "  'sentiment': 'neutral',\n",
      "  'sentiment_score': 0.99},\n",
      " {'Esto es una prueba.': {'laguage_score': 1.0,\n",
      "                          'translation': 'This is a test.'},\n",
      "  'sentiment': 'neutral',\n",
      "  'sentiment_score': 0.99},\n",
      " {'Dies ist ein Test.': {'laguage_score': 1.0,\n",
      "                         'translation': 'This is a test.'},\n",
      "  'sentiment': 'neutral',\n",
      "  'sentiment_score': 0.99},\n",
      " {'--*******-----******-------': {'laguage_score': 0.0,\n",
      "                                  'translation': '--*******-----******-------'},\n",
      "  'sentiment': 'neutral',\n",
      "  'sentiment_score': 0.94},\n",
      " {'Este es el texto numero 5': {'laguage_score': 1.0,\n",
      "                                'translation': 'This is text number 5'},\n",
      "  'sentiment': 'neutral',\n",
      "  'sentiment_score': 0.91},\n",
      " {'Yo soy un emoji 😀 de carita feliz': {'laguage_score': 1.0,\n",
      "                                        'translation': \"I'm a happy face emoji \"\n",
      "                                                       '😀'},\n",
      "  'sentiment': 'positive',\n",
      "  'sentiment_score': 0.99}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "for n,s in enumerate(sentiment):\n",
    "    value = s['sentiment']\n",
    "    scores = s['confidence_scores']\n",
    "    score = max(scores.values()) \n",
    "    translation_results[n]['sentiment'] = value \n",
    "    translation_results[n]['sentiment_score'] = score\n",
    "\n",
    "pprint( translation_results ) \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete application \n",
    "Using the python SDK \n",
    "\n",
    "Takes a list of strings in a given language. The language is detected for each and then translated to English.\n",
    "The sentiment is then analyzed for the translated documents. The result is a list of results, one per document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.translation.text import TextTranslationClient#, TranslatorCredential\n",
    "from azure.ai.translation.text.models import InputTextItem\n",
    "from azure.core.exceptions import HttpResponseError\n",
    " \n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "import pprint \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected languages of the input text: en with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: 'This is a test.'.\n",
      "Detected languages of the input text: en with score: 0.0.\n",
      "Text was translated to: 'en' and the result is: '--*******-----******-------'.\n",
      "Detected languages of the input text: en with score: 0.0.\n",
      "Text was translated to: 'en' and the result is: ''.\n",
      "Detected languages of the input text: en with score: 1.0.\n",
      "Text was translated to: 'en' and the result is: '44This is text number 5'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'This is a test.': {'translation': 'This is a test.', 'laguage_score': 1.0},\n",
       "  'sentiment': 'neutral',\n",
       "  'sentiment_score': 0.99},\n",
       " {'--*******-----******-------': {'translation': '--*******-----******-------',\n",
       "   'laguage_score': 0.0},\n",
       "  'sentiment': 'neutral',\n",
       "  'sentiment_score': 0.94},\n",
       " {'': {'translation': '', 'laguage_score': 0.0},\n",
       "  'sentiment': 'neutral',\n",
       "  'sentiment_score': 0.0},\n",
       " {'44This is text number 5': {'translation': '44This is text number 5',\n",
       "   'laguage_score': 1.0},\n",
       "  'sentiment': 'neutral',\n",
       "  'sentiment_score': 0.99}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_translation_multiple_inputs( text_translator, input_text_elements:list[str], to_language: list[str] ):\n",
    "    # [START get_text_translation_multiple_inputs]\n",
    "\n",
    "    results = []\n",
    "    if isinstance( to_language,str): to_language = [ to_language ]\n",
    "    try:\n",
    "        translations = text_translator.translate(body=input_text_elements, to_language=to_language)\n",
    "\n",
    "        for n,translation in enumerate(translations):\n",
    "            \n",
    "            language_score = translation.detected_language.score \n",
    "            language_translation = translation.translations[0].text if translation.translations else None\n",
    "\n",
    "            results.append( { input_text_elements[n] : { 'translation': language_translation, 'laguage_score': language_score}} ) \n",
    "            \n",
    "            print(\n",
    "                f\"Detected languages of the input text: {translation.detected_language.language if translation.detected_language else None} with score: {translation.detected_language.score if translation.detected_language else None}.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Text was translated to: '{translation.translations[0].to if translation.translations else None}' and the result is: '{translation.translations[0].text if translation.translations else None}'.\"\n",
    "            )\n",
    "\n",
    "    except HttpResponseError as exception:\n",
    "        if exception.error is not None:\n",
    "            print(f\"Error Code: {exception.error.code}\")\n",
    "            print(f\"Message: {exception.error.message}\")\n",
    "\n",
    "        return None \n",
    "    # [END get_text_translation_multiple_inputs]\n",
    "\n",
    "    return results \n",
    " \n",
    " \n",
    "def translation_and_sentiment( translator_client, text_analytics_client, documents, to_language = None ):\n",
    "    \n",
    "    if to_language is None:\n",
    "        to_language = ['en']\n",
    "    #is_error\n",
    "\n",
    "    translation_results = get_text_translation_multiple_inputs( translator_client, documents, to_language )\n",
    "    english_documents = [ value['translation'] for x in translation_results  for key, value in x.items()  ]\n",
    "\n",
    "    sentiment = text_analytics_client.analyze_sentiment(documents = english_documents )\n",
    "    for n,s in enumerate(sentiment):\n",
    "       \n",
    "        if not  s.is_error:\n",
    "            value = s['sentiment']\n",
    "            scores = s['confidence_scores']\n",
    "            score = max(scores.values()) \n",
    "            translation_results[n]['sentiment'] = value \n",
    "            translation_results[n]['sentiment_score'] = score\n",
    "        else: \n",
    "            translation_results[n]['sentiment'] = 'neutral' \n",
    "            translation_results[n]['sentiment_score'] = 0.0\n",
    "\n",
    "    return  translation_results\n",
    "\n",
    "\n",
    "key_translator      = os.environ[\"TRANSLATOR_KEY\"]\n",
    "location_translator = os.environ[\"TRANSLATOR_LOCATION\"]\n",
    "text_translator = TextTranslationClient(credential=AzureKeyCredential( key_translator ), region = location_translator )\n",
    "\n",
    "\n",
    "text_analytics_endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "text_analytics_key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=text_analytics_endpoint,credential=AzureKeyCredential(text_analytics_key))\n",
    "\n",
    "\n",
    "\n",
    "documents = ['This is a test.',\n",
    " '--*******-----******-------',\n",
    " \"\",\n",
    " \"44\"\n",
    " 'This is text number 5']\n",
    "\n",
    "translation_results = translation_and_sentiment( text_translator, text_analytics_client, documents  )\n",
    "translation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
